{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding Dropout impact.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3O87PyNXCYX8/y8GnkpM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peeush-agarwal/week-based-learning/blob/master/Deep-Learning/Dropout/Understanding_Dropout_impact.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Um46XNGBTkP",
        "colab_type": "text"
      },
      "source": [
        "# Dropout\n",
        "How does adding Dropout to Neural network helps reducing overfitting?\n",
        "\n",
        "To set the context, let's consider a very simple dataset (y = x), and complex Neural Network is designed to fit the dataset. \n",
        "+ Why simple dataset and complex NN?\n",
        "  + These conditions will let NN to overfit the dataset\n",
        "  + Then adding a Dropout layer will help in showing how does it help model not to overfit. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPumJIH0CWTB",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5L4QCv6CYMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.style.use('dark_background')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrVvFSNMCF7O",
        "colab_type": "text"
      },
      "source": [
        "## Generate dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA729ZviCFZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 100\n",
        "noise = 0.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16kAlQHzBJE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
        "Y_train = X_train + noise * torch.normal(torch.zeros((N, 1)), torch.ones((N, 1)))\n",
        "\n",
        "X_test = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
        "Y_test = X_test + noise*torch.normal(torch.zeros(N, 1), torch.ones(N, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLcZDKknDc2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.scatter(X_train.data.numpy(), Y_train.data.numpy(), color='purple', alpha=0.5, label='Train')\n",
        "plt.scatter(X_test.data.numpy(), Y_test.data.numpy(), color='orange',alpha=0.5, label='Test')\n",
        "plt.plot(np.linspace(-1, 1, N), np.linspace(-1, 1, N), 'g--', label='Actual function')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAptHoE6FZWm",
        "colab_type": "text"
      },
      "source": [
        "## Build a custom FC NN to learn the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHFT-p29FY_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(1, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 1)\n",
        ")\n",
        "\n",
        "model_dropout = nn.Sequential(\n",
        "    nn.Linear(1, 100),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8d4LaczGIA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "model_optim = optim.Adam(model.parameters(), lr=0.01)\n",
        "model_dropout_optim = optim.Adam(model_dropout.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYe-LZGrD6Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  model_optim.zero_grad()\n",
        "  outputs = model(X_train)\n",
        "  loss = loss_fn(outputs, Y_train)\n",
        "  loss.backward()\n",
        "  model_optim.step()\n",
        "\n",
        "  model_dropout_optim.zero_grad()\n",
        "  outputs_dropout = model_dropout(X_train)\n",
        "  loss_dropout = loss_fn(outputs_dropout, Y_train)\n",
        "  loss_dropout.backward()\n",
        "  model_dropout_optim.step()\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "\n",
        "    model.eval()\n",
        "    model_dropout.eval()\n",
        "\n",
        "    outputs_test = model(X_test)\n",
        "    loss_test = loss_fn(outputs_test, Y_test)\n",
        "\n",
        "    outputs_dropout_test = model_dropout(X_test)\n",
        "    loss_dropout_test = loss_fn(outputs_dropout_test, Y_test)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.scatter(X_train.data.numpy(), Y_train.data.numpy(), color='purple', alpha=0.5, label='Train')\n",
        "    plt.scatter(X_test.data.numpy(), Y_test.data.numpy(), color='orange', alpha=0.5, label='Test')\n",
        "    plt.plot(np.linspace(-1, 1, N), np.linspace(-1, 1, N), 'g--', label='Actual fn')\n",
        "    plt.plot(X_train.data.numpy(), outputs_test.data.numpy(), 'r', lw=3, label='Normal prediction')\n",
        "    plt.plot(X_test.data.numpy(), outputs_dropout_test.data.numpy(), 'b--', lw=3, label='Dropout prediction')\n",
        "    plt.title(f'E:{epoch}, loss:{loss_test.item():.4f}, loss_dropout:{loss_dropout_test.item():.4f}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    model.train()\n",
        "    model_dropout.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtcA1K6RLpYl",
        "colab_type": "text"
      },
      "source": [
        "Comparing above graphs, we can observe that NN without dropout overfits the given data, while model with dropout manages to not overfit to some extent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqT1inrbJBN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}