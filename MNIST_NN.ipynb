{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_NN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOw0Uyb/kkCacBjqCs3GbwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peeush-agarwal/week-based-learning/blob/master/MNIST_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgTZp_FoYtS7",
        "colab_type": "text"
      },
      "source": [
        "# Neural network for MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB1gWN9UYyoo",
        "colab_type": "text"
      },
      "source": [
        "MNIST (National Institute of Standards and Technology) provides us cleaned dataset of digits (0-9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs7L88YkZOmu",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeHkv8PrZN5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvRBBrCvcYZD",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset from PyTorch library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XlxlFP4YjZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = './Data'\n",
        "download = True\n",
        "batch_size = 100\n",
        "transform = transforms.Compose([transforms.ToTensor(), \n",
        "                                transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "trainset = datasets.MNIST(root=root_dir,train=True,transform=transform,download=download)\n",
        "testset = datasets.MNIST(root=root_dir, train=False, transform=transform, download=download)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkcwXB7ybk6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XHTrPS8dsw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = trainset.classes\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvNBXHgdt2_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Train size: {len(trainset)}')\n",
        "print(f'Test size: {len(testset)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "set1FQKgccMu",
        "colab_type": "text"
      },
      "source": [
        "## View random images from dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cz1a5s0cNUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs, classes = next(iter(trainloader))\n",
        "#print(type(inputs))\n",
        "#print(type(classes))\n",
        "#print(inputs.shape)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for idx, (img, cls) in enumerate(zip(inputs, classes)):\n",
        "    plt.subplot(10,10,idx+1)\n",
        "    plt.imshow(img.numpy().squeeze()) #Flatten the image matrix\n",
        "    #plt.title(f'Class:{cls}')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUY3ZaCWiypl",
        "colab_type": "text"
      },
      "source": [
        "## Build a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wte9NpSFdGu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicNN(nn.Module):\n",
        "    def __init__(self, inputs, outputs):\n",
        "        super(BasicNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(inputs, 10) # Hidden layer with 10 neurons\n",
        "        self.fc2 = nn.Linear(10, outputs) # Output layer\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        out = self.fc2(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-1HOGqlkW_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "net = BasicNN(input_size, output_size).to(device) # Image size = 28*28, Output classes = 10\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DunJC2cszVQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs):\n",
        "    loss_list = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            inputs = inputs.view(-1, input_size)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(inputs) # Forward propogation\n",
        "\n",
        "            loss = loss_func(outputs, labels) # Calculate loss\n",
        "\n",
        "            loss.backward() # Back propogation\n",
        "\n",
        "            optimizer.step()\n",
        "        loss_list.append(loss)\n",
        "    return loss_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_cBymunlspA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate():\n",
        "    accuracy_list = []\n",
        "    for batch, (images, labels) in enumerate(testloader):\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        images = images.view(-1, input_size)\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        total += len(images)\n",
        "        correct += (preds == labels).sum()\n",
        "\n",
        "        accuracy_list.append(100.0*correct/total)\n",
        "    return accuracy_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpKAZyOT5psi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(train_loss_list, eval_acc_list):\n",
        "    plt.subplot(121)\n",
        "    plt.plot(range(len(train_loss_list)), train_loss_list)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Training Loss')\n",
        "    plt.title('Training Loss over epochs')\n",
        "    \n",
        "    plt.subplot(122)\n",
        "    plt.plot(range(len(eval_acc_list)), eval_acc_list)\n",
        "    plt.xlabel('Batch (100)')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.title('Test Accuracy over batches of 100')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjoZ6sZaqZFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, num_epochs in enumerate([2, 5, 10, 20, 50, 100]):\n",
        "    print(f'Epochs={num_epochs}')\n",
        "    plot(train(num_epochs),evaluate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNY8J_C_vrAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}